# Staging Environment Configuration

# General Settings
aws_region   = "us-east-1"
name_prefix  = "litellm-staging"

# Default tags for all resources
default_tags = {
  Environment = "staging"
  Project     = "litellm"
  ManagedBy   = "terraform"
  Owner       = "your-team"
  CostCenter  = "engineering"
}

# VPC Configuration
vpc_cidr                 = "10.2.0.0/16"
public_subnet_cidrs      = ["10.2.1.0/24", "10.2.2.0/24"]
private_subnet_cidrs     = ["10.2.10.0/24", "10.2.20.0/24"]
database_subnet_cidrs    = ["10.2.100.0/24", "10.2.200.0/24"]
enable_nat_gateway       = true
single_nat_gateway       = false

# Security Configuration
allowed_cidr_blocks = ["10.0.0.0/8", "0.0.0.0/0"]  # More open than prod

# LiteLLM Configuration
litellm_port    = 4000
container_image = "ghcr.io/berriai/litellm:main-stable"  # Use custom image from litellm-app repo for PII guardrails

# Database Configuration
database_name     = "litellm"
database_username = "litellm"
# Database password is auto-generated
db_engine_version          = "15.8"
db_instance_class          = "db.t3.small"
db_allocated_storage       = 50
db_max_allocated_storage   = 200
db_storage_encrypted       = true
db_backup_retention_period = 7
db_multi_az               = false
db_deletion_protection    = false
db_skip_final_snapshot    = true

# ECS Configuration
ecs_cpu                   = 1024  # Moderate for staging LiteLLM container
ecs_memory               = 2048   # Moderate for staging without Ollama
ecs_desired_count        = 2
ecs_min_capacity         = 1
ecs_max_capacity         = 5
ecs_enable_autoscaling   = true
ecs_enable_execute_command = true

# ALB Configuration
health_check_path                = "/health/readiness"
health_check_interval           = 30
health_check_timeout            = 5
health_check_healthy_threshold  = 2
health_check_unhealthy_threshold = 3
alb_enable_deletion_protection  = false
alb_idle_timeout               = 60

# Additional Environment Variables for LiteLLM
environment_variables = {
  LITELLM_LOG_LEVEL = "INFO"
  LITELLM_DROP_PARAMS = "true"
}

# API Keys for LiteLLM Models
# REQUIRED: Add your OpenAI API key for the default gpt-4o-mini model
additional_ssm_parameters = {
  # Required: OpenAI API key for gpt-4o-mini model (default in config)
  "openai-api-key" = {
    value       = "sk-proj-your-openai-api-key-here"
    type        = "SecureString"
    description = "OpenAI API Key for LiteLLM"
  }
  
  # Optional: Uncomment additional providers as needed
  # "anthropic-api-key" = {
  #   value       = "sk-ant-your-anthropic-api-key-here"
  #   type        = "SecureString"
  #   description = "Anthropic API Key for Claude models"
  # }
  # 
  # "azure-api-key" = {
  #   value       = "your-azure-openai-key-here"
  #   type        = "SecureString"
  #   description = "Azure OpenAI API Key"
  # }
  # 
  # "azure-api-base" = {
  #   value       = "https://your-resource.openai.azure.com/"
  #   type        = "String"
  #   description = "Azure OpenAI API Base URL"
  # }
  # 
  # "google-api-key" = {
  #   value       = "your-google-api-key-here"
  #   type        = "SecureString"
  #   description = "Google API Key for Gemini models"
  # }
}
