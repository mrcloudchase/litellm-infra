# LiteLLM Configuration
# This configuration provides a minimal, functional setup for LiteLLM deployment
# 
# MINIMAL SETUP REQUIREMENTS:
# 1. At least one model (gpt-4o-mini is uncommented by default)
# 2. Add OPENAI_API_KEY to your terraform.tfvars additional_ssm_parameters
# 3. Deploy with: terraform apply -var-file="environments/dev/terraform.tfvars"
#
# TO ADD MORE MODELS:
# - Uncomment the desired model sections below
# - Add corresponding API keys to terraform.tfvars additional_ssm_parameters
# - Redeploy with terraform apply
#
# ADVANCED FEATURES:
# - All optional features are commented out for simplicity
# - Uncomment sections as needed for your use case

# Model List
model_list:
  - model_name: gpt-4o-mini
    litellm_params:
      model: openai/gpt-4o-mini
      api_key: os.environ/OPENAI_API_KEY

  # Optional: Additional OpenAI models (uncomment as needed)
  # - model_name: gpt-4o
  #   litellm_params:
  #     model: openai/gpt-4o
  #     api_key: os.environ/OPENAI_API_KEY
  #     
  # - model_name: gpt-3.5-turbo
  #   litellm_params:
  #     model: openai/gpt-3.5-turbo
  #     api_key: os.environ/OPENAI_API_KEY

  # Optional: Anthropic models (uncomment and add ANTHROPIC_API_KEY to SSM)
  # - model_name: claude-3-5-sonnet
  #   litellm_params:
  #     model: anthropic/claude-3-5-sonnet-20241022
  #     api_key: os.environ/ANTHROPIC_API_KEY
  #
  # - model_name: claude-3-haiku
  #   litellm_params:
  #     model: anthropic/claude-3-haiku-20240307
  #     api_key: os.environ/ANTHROPIC_API_KEY

  # Optional: Azure OpenAI models (uncomment and configure Azure credentials)
  # - model_name: azure-gpt-4o
  #   litellm_params:
  #     model: azure/gpt-4o
  #     api_base: os.environ/AZURE_API_BASE
  #     api_key: os.environ/AZURE_API_KEY
  #     api_version: "2024-02-01"

  # Optional: AWS Bedrock models (requires AWS credentials)
  # - model_name: bedrock-claude-3-sonnet
  #   litellm_params:
  #     model: bedrock/anthropic.claude-3-sonnet-20240229-v1:0
  #     aws_region_name: us-west-2

  # Optional: Google models (uncomment and add GOOGLE_API_KEY to SSM)
  # - model_name: gemini-pro
  #   litellm_params:
  #     model: gemini/gemini-1.5-pro
  #     api_key: os.environ/GOOGLE_API_KEY

# General Settings
general_settings:
  # Required: Master key for authentication (auto-generated by Terraform)
  master_key: os.environ/LITELLM_MASTER_KEY
  
  # Required: Database connection (auto-configured by Terraform)
  database_url: os.environ/DATABASE_URL
  
  # Required: Health check endpoint for ALB
  health_check: true
  
  # Recommended: Basic logging configuration
  set_verbose: false
  json_logs: true
  
  # Optional: Request timeout (uncomment to customize)
  # request_timeout: 600
  
  # Optional: CORS settings (uncomment to customize)
  # cors_origins: ["*"]
  
  # Optional: Rate limiting (uncomment to enable)
  # max_budget: 1000
  # budget_duration: 30d
  
  # Optional: Model fallbacks (uncomment when you have multiple models)
  # fallbacks:
  #   - ["gpt-4o", "gpt-4o-mini"]
  #   - ["claude-3-5-sonnet", "claude-3-haiku"]

# Advanced Features (Optional - Uncomment as needed)

# Optional: Router settings for load balancing multiple models
# router_settings:
#   routing_strategy: "usage-based-routing-v2"

# Optional: Redis caching (requires Redis setup)
# cache:
#   type: "redis"
#   host: os.environ/REDIS_HOST
#   port: 6379
#   password: os.environ/REDIS_PASSWORD

# Optional: Slack alerting (requires webhook configuration)
# alerting:
#   - service: "slack"
#     webhook_url: os.environ/SLACK_WEBHOOK_URL

# Optional: Content guardrails (requires additional setup)
# guardrails:
#   prompt_injection:
#     callbacks: ["presidio"]

# Optional: Logging and analytics callbacks
# success_callback: ["langfuse"]
# failure_callback: ["langfuse"]

# Optional: Langfuse integration for analytics
# langfuse:
#   public_key: os.environ/LANGFUSE_PUBLIC_KEY
#   secret_key: os.environ/LANGFUSE_SECRET_KEY
#   host: https://cloud.langfuse.com
